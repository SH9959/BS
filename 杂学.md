##### 多模态：

一开始我有这个想法，但是没听过这个词。他有以下几种任务：

**一、VQA（Visual Question Answering）视觉问答**

输入：一张图片、一个自然语言描述的问题

输出：答案（单词或短语）

**二、Image Caption 图像字幕**

输入：一张图片

输出：图片的自然语言描述（一个句子）

**三、Referring Expression Comprehension 指代表达**

输入：一张图片、一个自然语言描述的句子

输出：判断句子描述的内容（正确或错误）

**四、Visual Dialogue 视觉对话**

输入：一张图片

输出：两个角色进行多次交互、对话

**五、VCR (Visual Commonsense Reasoning) 视觉常识推理**

输入：1个问题，4个备选答案，4个理由

输出：正确答案，和理由

##### 正态KL散度

[(368条消息) 正态分布的KL散度_MatrixCancer的博客-CSDN博客](https://blog.csdn.net/int_main_Roland/article/details/124650909#:~:text=记 q(x) %3D N (x%3Bμ1%2Cσ12)%2Cp(x) %3D N (x%3Bμ2%2Cσ22)%2Cϕ(x),(∫ q(x)x2dx) 

[KL散度(Kullback-Leibler Divergence)介绍及详细公式推导 | HsinJhao's Blogs](https://hsinjhao.github.io/2019/05/22/KL-DivergenceIntroduction/#more)

##### 最小编辑距离

[(368条消息) 最小编辑距离_何如千泷的博客-CSDN博客](https://blog.csdn.net/qq_42735631/article/details/123723851#:~:text=最小编辑距离计算 1 d [i-1] [j] 表示 words1 前,words1 的第 i 个字符和 words2 的第 j 个字符不相同，只需将其中一个替换成另一个，反之则不需要进行操作)

```python
def minDistance(words1: str, words2: str) -> int:
    m = len(words1)
    n = len(words2)
    
    if m == 0 or n == 0:
        return m + n 
    
    dp = [[0] * (n + 1) for _ in range(m + 1)]
    
    for i in range(m+1):
        dp[i][0] = i 
    
    for i in range(n+1):
        dp[0][i] = i 
    
    for i in range(1, m+1):
        for j in range(1, n+1):
            left = dp[i][j-1] + 1
            down = dp[i-1][j] + 1
            if words1[i-1] == words2[j-1]:
                left_down = dp[i-1][j-1]
            else:
                left_down = dp[i-1][j-1] + 1
            dp[i][j] = min(left, down, left_down)
            
    return dp[m][n]

if __name__=='__main__':
    words1 = input()
    words2 = input()
    print(minDistance(words1, words2))

```

##### 无监督的迭代学习

聚类

识别？



##### 项目

核心技术+应用技术

和数据集

应用场景

ASR,TTS,对话，视觉，手眼标定，建立坐标系，路径规划。

流程：

- 用户语音指令（ASR）T2S,Text2Speech
- 机器人NLU（intent、slot填充），NLG
- DM对话管理、任务管理
- **视觉（手眼标定、物体识别目标检测，轨迹追踪，...分割）**将模仿参考segment anything将defusion，prompt交互技术迁移到在检测和追踪上的应用，参考大模型新技术，分割（facebook）。
- 路径规划，动作规划
- 其他，传感器

##### python参数

TypeError:多值错误 multiple values

语法错误：SyntaxError: positional argument follows keyword argument

##### 组合优化问题

组合优化问题，知乎：[组合优化问题（Combinatorial optimization problem, COP） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/548324577)





## 讲解工作

看论文时至少得探清所有自然的疑问。

概念，定义

## 代码库学习

### Path

```python
from pathlib import Path  # 导入Path类

# 获取当前文件的父级目录的父级目录，并转换为绝对路径
wd = Path(__file__).parent.parent.resolve()

# 将该路径添加到系统路径中
sys.path.append(str(wd))

```

## 代码规范

### 装饰器

```python
# demo 1
def debug(func):
    def wrapper():
        print("[DEBUG]: enter {}()".format(func.__name__))
        return func()
    return wrapper

@debug
def hello():
    print("hello")

hello()
#------------output-----------------
#>>>[DEBUG]: enter hello()
#>>>hello
```



```python
def timer(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f"Function {func.__name__} TIME: {end_time - start_time} s")
        return result
    return wrapper
```



### wandb

[wandb: 深度学习轻量级可视化工具入门教程_wandb教程-CSDN博客](https://blog.csdn.net/qq_40507857/article/details/112791111)



### Debug

```python
import sys
if debug: 
    print("here is :",__file__,sys._getframe().f_lineno)
```



```python
class SampleClass(object):
    """这里是类的概述.

    这里是更多信息....
    这里是更多信息....

    属性:
        likes_spam: 布尔值, 表示我们是否喜欢午餐肉.
        eggs: 用整数记录的下蛋的数量.
    """

    def __init__(self, likes_spam = False):
        """用某某某初始化 SampleClass."""
        self.likes_spam = likes_spam
        self.eggs = 0
# TODO(crbug.com/192795): 研究 cpufreq 的优化.
# TODO(你的用户名): 提交一个议题 (issue), 用 '*' 代表重复.
    def public_method(self):
        """执行某某操作."""
```

```python
def fetch_smalltable_rows(
    table_handle: smalltable.Table,
    keys: Sequence[bytes | str],
    require_all_keys: bool = False,
) -> Mapping[bytes, tuple[str, ...]]:
    """从 Smalltable 获取数据行.

    从 table_handle 代表的 Table 实例中检索指定键值对应的行. 如果键值是字符串,
    字符串将用 UTF-8 编码.

    参数:
        table_handle: 处于打开状态的 smalltable.Table 实例.
        keys: 一个字符串序列, 代表要获取的行的键值. 字符串将用 UTF-8 编码.
        require_all_keys: 如果为 True, 只返回那些所有键值都有对应数据的
            行.

    返回:
        一个字典, 把键值映射到行数据上. 行数据是字符串构成的元组. 例如:

        {b'Serak': ('Rigel VII', 'Preparer'),
         b'Zim': ('Irk', 'Invader'),
         b'Lrrr': ('Omicron Persei 8', 'Emperor')}

        返回的键值一定是字节串. 如果字典中没有 keys 参数中的某个键值, 说明
        表格中没有找到这一行 (且 require_all_keys 一定是 false).

    抛出:
        IOError: 访问 smalltable 时出现错误.
    """
```

```python
from collections.abc import Mapping, Sequence
import os
import sys
from typing import Any, NewType
```

```python
import collections
import queue
import sys

from absl import app
from absl import flags
import bs4
import cryptography
import tensorflow as tf

from book.genres import scifi
from myproject.backend import huxley
from myproject.backend.hgwells import time_machine
from myproject.backend.state_machine import main_loop
from otherproject.ai import body
from otherproject.ai import mind
from otherproject.ai import soul
```





```python
import argparse
import os
if __name__ == "__main__":
    # parse args
    parser = argparse.ArgumentParser(description='test')
    parser.add_argument('-d', '--debug', action='store_true', help='debug mode')
    args, _ = parser.parse_known_args()
    if args.debug:
        # if you use vscode on hpc-login-01
        import debugpy
        debugpy.connect(('192.168.1.50', 6789))
        debugpy.wait_for_client()
        debugpy.breakpoint()

```



## 换源操作

[Anaconda 换国内源、删源最全集锦（转载） - 一颗蘑菇头 - 博客园 (cnblogs.com)](https://www.cnblogs.com/yikemogutou/p/11396045.html)

## 虚拟机

#### 知识点

>[MobaXterm与VMware虚拟机SSH连接不成功问题解决_mobaxrerm ssh 连接不上, 自带ssh可以-CSDN博客](https://blog.csdn.net/super_Zhu0818/article/details/108034931)

记得打开虚拟机的ssh服务

```bash
sudo yum update
sudo yum install openssh-server

sudo systemctl start sshd  #前面只是安装，主要是这句打开

sudo systemctl restart sshd
```



#### 配置静态ip

>[ubuntu22.04配置静态ip - 搜索 (bing.com)](https://cn.bing.com/search?q=ubuntu22.04配置静态ip&qs=n&form=QBRE&sp=-1&lq=0&pq=ubuntu22.04配置静态ip&sc=10-17&sk=&cvid=2A08403582E44406A6F9E3E060B4FA52&ghsh=0&ghacc=0&ghpl=)

1、找到配置文件

```bash
gedit /etc/netplan/01-network-manager-all.yaml
```

2、修改（22.04）：

网关地址看

![image-20231211140753850](杂学.assets/image-20231211140753850.png)

```yaml
network:
    ethernets:
        ens33:
            dhcp4: no
            dhcp6: no
            addresses:
                - 192.168.202.10/24
            routes:
                - to: default
                  via: 192.168.202.2
            nameservers:
                addresses:
                    - 114.114.114.114
                    - 8.8.8.8
    version: 2
    renderer: networkd

```

（20.04/18.04）

```yaml
network:
    ethernets:
        ens33:
            dhcp4: no
            addresses: [192.168.1.10/24]
            optional: true
            gateway4: 192.168.1.1
            nameservers:
                    addresses: [114.114.114.114,8.8.8.8]
 
    version: 2

```

3、应用

```
sudo netplan apply
```



# 平板上连接hpc

## 平板与termux传文件

先下载termux

微信上保存本地，一般是保存到了`/sdcard/Download/WeiXin`

```
termux-setup-storage  # 打开存储权限
cp /sdcard/Download/WeiXin/id_rsa.pub ~/.ssh/id_rsa.pub
cp /sdcard/Download/WeiXin/id_rsa ~/.ssh/id_rsa
cp /sdcard/Download/WeiXin/config ~/.ssh/id_rsa
```

> 记得连接HIT-WLAN
>
> 

## 服务器传文件到平板

```
scp -r hpc:~/cdt/NotearsNonlinear_submission /sdcard/Download
```



## 科研思维

- 看到某个具体的任务，脑海里应该想到什么





## 找论文

connected paper以文章为核心，所以输入综述文章会不会更好？

# 关于在server和client之间传输图像

由于json无法直接处理Image格式的图像，故需要将其转为某种格式，如果转成列表`.tolist`再当作文本格式处理，内存会大幅增加，理论计算大概是2k二进制图像变成10多M。所以需要想别的办法。

![image-20240107183637327](杂学.assets/image-20240107183637327.png)

#### 法一：base64

````
要在 JSON 格式中发送 PIL.Image 类型的图片，你需要将图片转换为一种可以被 JSON 编码的格式。一般来说，可以将图片转换为 base64 编码的字符串。下面是一个如何实现这个过程的步骤：

1. **导入必要的库**：你需要 `PIL` 来处理图片，以及 `base64` 和 `io` 来进行编码转换。

2. **打开或创建一个 PIL 图片**：如果你已经有一个 `PIL.Image` 对象，可以直接使用；如果是从文件中加载图片，可以使用 `PIL.Image.open`。

3. **将 PIL 图片转换为字节流**：可以使用 `io.BytesIO` 对象作为一个临时的缓冲区来存储图片数据。

4. **将字节流编码为 base64 字符串**：使用 `base64` 模块对字节流进行编码。

5. **将 base64 字符串嵌入到 JSON 对象中**：现在你可以将编码后的字符串作为 JSON 对象的一部分。

6. **发送 JSON**：最后，你可以通过网络发送这个 JSON 对象。

以下是这个过程的示例代码：

```python
import base64
import io
from PIL import Image
import json

# 假设你有一个 PIL.Image 对象
image = Image.open('path_to_your_image.jpg')  # 或者你的 PIL.Image 对象

# 将图片转换为字节
buffered = io.BytesIO()
image.save(buffered, format="JPEG")
img_str = base64.b64encode(buffered.getvalue()).decode()

# 将 base64 字符串嵌入 JSON
json_data = json.dumps({"image": img_str})

# 现在你可以通过网络发送 'json_data'
# ...
```

这段代码演示了如何将一个 PIL 图片对象转换为 base64 编码的字符串，并将其嵌入 JSON 对象中。需要注意的是，这种方式会增加数据的大小，因为 base64 编码比原始的二进制数据大约增加 33%。因此，这种方法适用于较小的图片和不太频繁的网络传输。对于大型图片或高频传输，可能需要考虑更有效的数据传输方案。
````

#### 循环接受长数据

一个问题是，改变buffer_size发现能接受的长度不一样？这是为什么？

`recv`函数的`flag`参数可以有一个选项是：`MSG_WAITALL`，书上说，这表示在接收的时候，函数一定会等待接收到指定`size`之后才会返回

```
recv
```

`sendall()`是对`send()`的包装，完成了用户需要手动完成的部分，它会自动判断每次发送的内容量，然后从总内容中删除已发送的部分，将剩下的继续传给`send()`进行发送

一个可能的解释：网络传输的限制：即使你设置了很大的 `bufsize` 值，也不一定能一次性接收到超过网络传输限制的数据量。例如，如果发送方以较小的数据块进行发送，即使你设置了较大的 `bufsize`，也只能接收到发送方所发送的数据块大小。

[Linux IO函数的使用和区别 - 橙&子 - 博客园 (cnblogs.com)](https://www.cnblogs.com/orange1438/p/4613460.html#:~:text=recv函数用于,ket函数返回。)

```
在 Python 中，recv() 方法的 bufsize 参数表示一次最多接收的数据量，单位为字节。

Python 的 socket 模块没有明确规定 bufsize 的最大值。实际上，可以设置非常大的值，但受到以下几个因素的限制：

操作系统的限制：不同操作系统对于单次 recv() 调用的最大缓冲区大小可能有限制。例如，在某些系统上，最大限制可能是 64KB 或 1MB。你可以通过查看特定操作系统的文档或参考相关文档来了解更多细节。

系统的可用内存：如果你设置的 bufsize 太大，超过了系统可用的内存限制，可能会导致内存溢出错误。

网络传输的限制：即使你设置了很大的 bufsize 值，也不一定能一次性接收到超过网络传输限制的数据量。例如，如果发送方以较小的数据块进行发送，即使你设置了较大的 bufsize，也只能接收到发送方所发送的数据块大小。

综上所述，虽然没有明确规定 bufsize 的最大值，但你应该根据你的系统资源和网络条件来选择合适的值，避免超过系统的限制和网络传输的限制。通常，使用较小的缓冲区大小（如几千字节）进行多次接收是更常见的做法。
```

[Python网络编程04 /recv工作原理、展示收发问题、粘包现象 - LBZHK - 博客园 (cnblogs.com)](https://www.cnblogs.com/liubing8/p/11366648.html)

# VSCODE

`.vscode` ：很多操作和插件都会基于所在目录生成相关的配置文件，而这些文件通常都会被保存到所在目录的`.vscode`文件夹中。`.vscode` 文件夹中的各种配置决定了不同目录被打开时 VS Code 会启动哪些插件和配置。



# Git

## git白色箭头解决

[解决github文件夹有向右的白色箭头并且不能打开的解决办法 - G0mini - 博客园 (cnblogs.com)](https://www.cnblogs.com/pangya/p/15979539.html#:~:text=解决github文件夹有向右的白色箭头并且不能打开的解决办法 - G0mini - 博客园 问题如图 解决方案 删除子文件夹里面的.git文件,-m "commit messge" 执行git push origin [ branch_name])

## git原理

[这才是真正的Git——Git内部原理揭秘！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/96631135)

## 一些git操作

```bash
git init
git add .                                           #   这个点也可以是某个文件
git status
git commit -m “上传以下文件”
git push
git remote add origin https://xxx@xxx/test.git
git push origin master                     #  ssl失败就用git config --global http.sslverify false关掉报错

https://blog.csdn.net/weixin_45309916/article/details/108273988
#挺详细

git checkout -b main  # 切换分支

git push origin --delete [branchname]
git fetch -p

#如何修改
git config --global --add safe.directory "*"# 取消报错
git config --global core.autocrlf true # 取消报错
git add .
git commit -m "后续修改的"
git config --global user.email "1572958043@qq.com"# 应该是用于认证
git config --global http.sslverify false# 取消报错
git push
git pull --rebase origin main #这是远程更新合并到本地。
git push origin HEAD:main


#在远端更改，如何同步本地呢？

```

删除所有__pycache__

```bash
find . -name "__pycache__" -type d -exec git rm -r --cached {} +
```

删除指定文件文件夹以外的其他文件.

```bash
find . -maxdepth 1 ! -name 'EasyEdit' ! -name '.git' ! -name '.' -exec git rm -rf {} \;
# 文件

find . -type d ! -name 'EasyEdit' ! -name '.git' -prune -exec git rm -rf {} \;
# 文件夹hh,毕设全没了
```

[github](https://github.com/serengil/deepface)



**新连接**

git远端新建仓库

本地

```zsh
git init
git add .
git remote add origin http://[你的仓库]
git branch --set-upstream-to=origin/main main

# 如果远端添加了README.md
git pull origin main --allow-unrelated-histories

git push origin main
```




# import 路径问题

```
GPT3.5:
如果你使用绝对路径导入包（例如`import package_name`），Python会默认从sys.path中的目录中查找该包。sys.path中的第一个目录是当前工作目录。

如果你使用相对路径导入包（例如`from .package_name import module_name`），那么路径是相对于当前文件所在的目录。其中点（.）表示当前文件所在的目录。

需要注意的是，模块搜索路径是由Python的sys.path设置决定的。sys.path包括了一些默认的目录，如当前工作目录、PYTHONPATH环境变量指定的目录以及Python安装时默认的库目录。


```

[python导入的模块搜索顺序详解（python import搜寻模块的机制详解）_python import导入顺序-CSDN博客](https://blog.csdn.net/qq_27825451/article/details/100552739)

```
|
V
总结：
python搜索模块的顺序为如下：

内建模块 >

程序的根目录（即当前运行python文件的目录）>

PYTHONPATH环境变量设置的目录>

标准库的目录>

任何能够找到的*.pth文件的内容>

第三方扩展的site-package目录
```



```python
##查看当前库路径
import groundingdino
import os

module_path = os.path.abspath(groundingdino.__file__)
print(module_path)
```

# python与C

```
#GPT3.5
好的，如果 groundingdino.py 中确实没有 _C 方法，那么这可能说明该模块没有被正确地编译或构建。_C 方法通常是在使用 C 或 C++ 语言编写的 Python 扩展模块中定义的，这些模块需要使用 Python 的 C API 与解释器进行交互。

如果 _C 方法是在 C/C++ 代码中定义的，那么你需要先将代码编译为共享库或动态链接库（.so 或 .dll 文件），然后才能在 Python 中使用。你可以使用 Python 的 distutils 模块或其他构建工具来自动化这个过程。

另外，如果你使用的是 PyTorch，你可以考虑使用 PyTorch 提供的 torch.utils.cpp_extension 模块来编译和加载 C++ 扩展。这个模块可以自动处理编译和链接过程，并且可以与 PyTorch 的 JIT 编译器结合使用，使得 C++ 扩展可以被 JIT 编译为 GPU 上的 CUDA 代码。
```

```python
#python查看cuda
>>> torch.cuda.is_available()
True
>>> torch.cuda.device_count()
1
>>> torch.cuda.device(1)
<torch.cuda.device object at 0x7fcedc29d210>
>>> torch.cuda.device(0)
<torch.cuda.device object at 0x7fce2a05d390>
>>> torch.cuda.device(2)
<torch.cuda.device object at 0x7fcedc29d210>
>>> torch.cuda.device(3)
<torch.cuda.device object at 0x7fce2a05d780>
>>> torch.cuda.device(4)
<torch.cuda.device object at 0x7fcedc29d210>
>>> torch.cuda.device(5)
<torch.cuda.device object at 0x7fce2a05d5d0>
>>> torch.cuda.device(6)
<torch.cuda.device object at 0x7fcedc29d210>
>>> torch.cuda.device(7)
<torch.cuda.device object at 0x7fce2a05d960>
>>> torch.cuda.device(8)
<torch.cuda.device object at 0x7fcedc29d210>
>>> torch.cuda.device(9)
<torch.cuda.device object at 0x7fce2a05d9c0>
>>> torch.cuda.device(10)
```

# cuda pytorch cudnn关系

[深度学习|如何确定 CUDA+PyTorch 版本 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/658800083)

```
import torch

with torch.cuda.device(1):
    # 在此代码块中，cuda:1 是活动设备
    # 创建的所有 CUDA 张量和模型都将使用 cuda:1 设备

```

```
import torch

device = torch.device('cuda:1')
torch.cuda.set_device(device)

```

```
import torch

if torch.backends.cudnn.is_available():
    print("cuDNN is available")
else:
    print("cuDNN is not available")

```

```

# 设置当前活动的CUDA设备为cuda:1
torch.cuda.set_device(1)
torch.backends.cudnn.init()
x = torch.tensor([1, 2, 3]).to('cuda:1')
```

查看CUDA版本

```
nvcc --version
nvidia-smi
```

```python
#python
import torch
print(torch.version.cuda)

```

下载后nvidia-smi 和nvcc都显示12.2，而执行python import torch   torch.version.cuda显示12.1，pip list里面也有12.1的组件

pytorch版本为与最新的CUDA兼容，torch的cuda版本未更新：需要重新安装torch

查看torch版本

```
>>> import torch
>>> torch.__version__
'2.1.2+cu121'

pip install torch==2.1.2+cu122 -f https://download.pytorch.org/whl/cu122/torch_stable.html

```



```
conda install pytorch cudatoolkit=12.2 -c pytorch

# 运行之后还是没更新，pip list里还是12.1
pip install torch==<torch_version>+cu<cuda_version> -f https://download.pytorch.org/whl/cu<cuda_version>/torch_stable.html

```

下载nvcc

```
conda install nvidia/label/cuda-12.1.0::cuda
```

|       |                                                              |
| ----- | ------------------------------------------------------------ |
| CPU   | GPU                                                          |
| C++,C | NVCC(NVIDIA CUDA Compiler的缩写，它是一种专门为GPU计算设计的C++编译器。) |
| C程序 | CUDA（CUDA C程序"".cu"）                                     |



```
根据您提供的信息，您的GPU驱动程序版本是535.129.03，CUDA版本是12.2。这意味着您的系统已安装了CUDA 12.2。

如果您之前下载并安装了CUDA 12.1，但现在显示的是CUDA 12.2，可能有以下几个原因：

您可能在安装过程中选择了升级到CUDA 12.2版本。在安装过程中，可能会询问您是否要升级或保留现有版本。如果您选择了升级，那么旧的CUDA 12.1版本将被替换为新的CUDA 12.2版本。

您可能在安装CUDA 12.2之后未完全卸载之前的CUDA 12.1版本。在安装新版本之前，最好先卸载旧版本的CUDA，以避免冲突和混乱。请确保在安装新版本之前完全删除旧版本。

您可能有多个CUDA版本同时安装在您的系统上，并且当前环境变量设置指向了CUDA 12.2。请检查您的环境变量（例如PATH和LD_LIBRARY_PATH），确保它们正确指向所需的CUDA版本。

请注意，nvidia-smi命令显示的是您当前系统中安装的NVIDIA GPU驱动程序和CUDA版本，并不一定反映您下载的具体CUDA Toolkit版本。如果您需要使用特定版本的CUDA Toolkit进行开发，您需要在编译和链接代码时明确指定所需的CUDA版本。
```

# conda与pip

[如何在conda环境中正确地使用pip_conda pip-CSDN博客](https://blog.csdn.net/qq_44856695/article/details/131378398)

> 记住conda create -n myenv python=3.12要一起

# 烦人的pip

当您使用`conda activate`激活虚拟环境后，pip应该会自动切换到与该环境关联的pip。

如果您在激活虚拟环境后仍然看到系统的pip而不是虚拟环境的pip，可能是由于以下原因之一：

1. 虚拟环境没有正确地创建或配置：请确保使用`conda create`命令正确地创建了虚拟环境，并且在创建环境时没有指定`--no-pip`选项。另外，请检查虚拟环境中是否存在pip工具，可以尝试重新创建虚拟环境来解决问题。
2. 未正确安装虚拟环境中的pip：在激活虚拟环境后，运行`which pip`命令来确定使用的pip的路径。如果显示的不是虚拟环境中的路径，可能是因为pip没有正确地安装在虚拟环境中。您可以尝试重新安装虚拟环境中的pip，使用命令`conda install pip`或`pip install --upgrade pip`来安装或更新pip。
3. 系统的pip覆盖了虚拟环境的pip：有些操作系统（如Windows）可能会将系统的pip添加到PATH环境变量中，并且优先级较高。这可能导致在激活虚拟环境后仍然使用系统的pip。您可以尝试在激活虚拟环境后手动运行虚拟环境中的pip，例如使用完整路径或使用`python -m pip`命令来确保使用的是虚拟环境中的pip。

# 关于终端

```
srun --gres=gpu:a100-sxm4-80gb:1 --mem 64g -t 8:00:00  --pty bash -i
```

`--pty`

```
--pty

伪终端（pseudo terminal）和终端（terminal）是两个不同的概念，但它们在某些方面有相似之处。

终端通常指的是由计算机直接连接的用户界面设备，例如电传打字机、CRT显示器或现代计算机上的终端模拟器。它们允许用户通过键盘输入和显示器输出与计算机进行交互，并且可以运行各种应用程序和命令行工具，例如shell、编辑器、编译器等。终端通常可以处理各种控制字符和终端设置，以便用户可以自定义其外观和行为。

伪终端是一种虚拟终端设备，通常用于在进程之间或进程和计算机之间创建交互式通信会话。它包括一个主设备（master device）和一个从设备（slave device），其中主设备是伪终端的控制者，而从设备则提供了与终端设备类似的交互式界面。伪终端通常用于运行shell、远程登录和其他需要与用户进行交互的程序。

因此，伪终端和终端都是用于与计算机进行交互的设备或会话，但伪终端是一种虚拟设备，在进程和计算机之间建立交互式通信会话，而终端则是一种实际的设备，直接连接到计算机。
```

```
-i
在srun命令中，-i选项表示创建一个交互式会话。它告诉作业调度系统在分配资源后，启动一个交互式终端（例如bash），以便用户可以直接与该终端进行交互。
```

# __init__.py

```
__init__.py 文件是 Python 包（Package）中的一个特殊文件。它的作用如下：

包标识：__init__.py 文件告诉 Python 解释器该目录是一个包，可以被导入和使用。

初始化代码：__init__.py 文件可以包含初始化代码，用于在导入包时执行一些操作。例如，可以在 __init__.py 中定义全局变量、导入子模块或执行其他初始化任务。

控制包的导入行为：通过在 __init__.py 中定义 __all__ 变量，可以控制在使用 from package import * 语句时导入哪些模块或变量。

提供包级别的接口：可以在 __init__.py 中导入其他模块，并将其公开为包的一部分。这样，用户可以直接从包级别访问这些模块，而不需要逐个导入子模块。

总而言之，__init__.py 文件在 Python 包中具有重要的作用，用于标识包、执行初始化代码、控制导入行为等。它是构建和组织包的基础。
```

```
如果在 __init__.py 文件中写入了上述代码，那么在导入该包时，这些模块和函数将自动导入并可以直接使用。

如果不在 __init__.py 文件中写入这些代码，那么在需要使用这些模块或函数时，需要分别导入它们的模块。例如，如果需要使用 build_model 函数，需要在代码中添加 from .models import build_model。

因此，将这些常用的模块和函数写入 __init__.py 文件中，可以使包的使用更加方便和简洁，同时也可以提高代码的可读性。但是，如果包中的模块和函数过多，或者这些模块和函数只在某些情况下使用，也可以选择不将其写入 __init__.py 文件中，而是根据需要进行导入。

总之，是否将模块和函数写入 __init__.py 文件中，应根据实际情况和个人喜好来决定。
```

# BERT

```
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
import torch

# 假设我们有一些数据用于训练
texts = ["I love this!", "This is bad."]
labels = [1, 0]  # 假设 1 是正面情绪，0 是负面情绪

# 加载预训练的BERT模型和分词器
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased')

# 对文本进行编码
inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
input_ids = inputs["input_ids"]
attention_mask = inputs["attention_mask"]

# 将标签转换成tensor
labels = torch.tensor(labels).unsqueeze(0)

# 定义优化器
optimizer = AdamW(model.parameters(), lr=1e-5)

# 训练模式
model.train()

# 假设我们只跑一个非常简单的训练循环
for epoch in range(4):  # 循环次数应该根据实际需要设置
    optimizer.zero_grad()
    
    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
    loss = outputs.loss
    loss.backward()
    optimizer.step()

    print(f"Epoch {epoch}, Loss: {loss.item()}")

# 保存模型权重
model.save_pretrained('/path/to/save/model')

# 加载模型权重
model = BertForSequenceClassification.from_pretrained('/path/to/save/model')

# 推理模式
model.eval()

# 对一段新文本进行推理
new_texts = ["This is great!"]
new_inputs = tokenizer(new_texts, return_tensors="pt")
with torch.no_grad():
    new_outputs = model(**new_inputs)
    logits = new_outputs.logits
    predictions = torch.argmax(logits, dim=-1)

print(predictions)

```

```
from transformers import BertTokenizer, BertForSequenceClassification
import torch

def bert_inference(text):
    # Load the pre-trained BERT tokenizer
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

    # Encode the input text
    encoded_input = tokenizer(text, return_tensors='pt')

    # Load the pre-trained BERT model for sequence classification
    model = BertForSequenceClassification.from_pretrained('bert-base-uncased')

    # Put the model on cuda:1 device
    device = 'cuda:1'
    model.to(device)

    # Put model in evaluation mode
    model.eval()

    # Run the model and get the logits
    with torch.no_grad():
        # Move the input tensors to the cuda:1 device
        encoded_input = {k: v.to(device) for k, v in encoded_input.items()}
        output = model(**encoded_input)

    # The output has the shape (batch size, num labels)
    logits = output.logits

    return logits

# Example usage:
text_to_classify = "Hello, how are you doing today?"
logits = bert_inference(text_to_classify)
print(logits)

```

# （在线，离线）强化学习、模仿学习

```
强化学习（Reinforcement Learning）是一种机器学习方法，用于训练智能体（Agent）从环境中不断进行试错学习，以最大化累计奖励。在强化学习中，智能体通过与环境进行交互，从环境中观察状态，并针对当前状态执行动作，然后根据环境的反馈获得奖励信号，以引导智能体的行为。智能体的目标是学习一个策略（Policy），以最大化累计奖励。

强化学习通常包括以下组件：

状态（State）：表示环境的当前状态，可能是连续或者离散的。

动作（Action）：智能体根据当前状态选择执行的操作。

奖励（Reward）：表示智能体在当前状态执行动作后获得的反馈，可以是正或负的数值。

策略（Policy）：表示智能体在当前状态下选择动作的概率分布。

值函数（Value Function）：表示智能体在状态或状态-动作对上能够获得的期望累计奖励，用于指导智能体的决策。

环境模型（Environment Model）：描述智能体与环境之间的交互方式，包括状态转移概率和奖励函数等。

强化学习方法可以基于模型或者无模型。基于模型的方法可以利用环境模型进行规划，从而预测智能体在未来状态下的表现，并指导智能体的行为。无模型方法则直接从交互数据中学习策略或值函数等，而不需要显式地建立环境模型。

强化学习具有广泛的应用场景，如机器人控制、游戏智能、自然语言处理等。但是，强化学习也存在着许多挑战和限制，例如稳定性、样本效率、泛化能力等问题。因此，在实际应用中需要根据具体问题选择合适的算法和技术，以提高强化学习的效果和性能。
```



```
离线强化学习（Offline Reinforcement Learning）是一种强化学习的方法，它与传统的在线强化学习方法有所不同。在线强化学习通常通过与环境的交互来进行学习，智能体通过观察环境的反馈，使用实时生成的样本来更新策略。而离线强化学习则是在事后收集到的已保存的离线数据集上进行学习，而不需要与环境进行实时交互。

离线强化学习的主要挑战在于数据的有效利用。由于数据是事先收集的，可能存在以下问题：

样本选择偏差（Sample Selection Bias）：离线数据集往往是在特定的策略下生成的，因此可能存在数据的分布与目标策略的分布不匹配的问题。

高方差（High Variance）：离线数据集中的样本可能具有较高的方差，这意味着从中学习到的策略可能不稳定。

为了应对这些挑战，离线强化学习采用了一系列方法和技术，例如重要性采样（Importance Sampling）、动态规划技术、行为克隆（Behavior Cloning）等。

离线强化学习在一些场景中具有重要的应用价值。例如，在某些实际问题中，与环境进行交互收集数据可能非常昂贵或危险，而利用已有的离线数据可以更有效地进行学习。此外，离线强化学习还可以利用历史数据来进行策略改进和优化，使得智能体在真实世界中的表现更加稳定和可靠。
```





```
模仿学习（Imitation Learning）是一种基于监督学习的强化学习方法，旨在通过学习参考策略（Expert Policy）的行为来指导智能体的决策。在模仿学习中，智能体不需要与环境进行交互，只需要观察参考策略在环境中的表现，并建立一个模型来学习参考策略的行为。

模仿学习通常包括以下步骤：

收集参考策略的轨迹数据（Trajectory Data）：参考策略可以是人类专家、其他智能体或者预训练的模型，在环境中执行任务并收集状态动作对序列作为参考数据。

训练模型：将参考数据作为训练数据，使用监督学习算法（如神经网络）构建模型来学习参考策略的行为。

评估模型：使用测试数据对训练得到的模型进行评估，以确定其性能和效果。

模仿学习相较于传统的强化学习方法具有以下优点：

简单高效：模仿学习不需要与环境进行交互，可以直接从轨迹数据中学习参考策略的行为，因此更加高效。

可控性强：参考策略的行为可以直接控制模型的学习过程，因此可以更好地控制智能体的行为。

支持多任务学习：通过收集不同参考策略的数据，可以在单个模型中支持多个任务的学习。

模仿学习也存在一些挑战和限制，例如参考策略的质量、样本分布以及泛化能力等问题。因此，在实际应用中需要根据具体情况选择合适的方法和技术，以提高模仿学习的效果和性能。
```

# PDDL

PDDL solver是一种用于求解规划问题的软件工具，它使用规划领域定义语言（PDDL）来描述问题。PDDL是一种用于表示规划问题的标准语言，它能够描述问题的状态空间、动作空间以及目标条件。PDDL solver通过分析问题的PDDL描述，找到一个合适的规划方法，以解决给定的规划问题。



# 温度系数

![image-20240217064930784](杂学.assets/image-20240217064930784.png)

# SORA(待了解)

NaVIT、

DiT、

V2VE、

Latent隐空间设计

# backward四方程

[【深度学习篇】：前向传播（forward）和反向传播（backward） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/447113449)

# GLUE

1. 语言学可接受性（CoLA）
2. 识别文本蕴涵（RTE）
3. 推理问题回答（QNLI）
4. 对抗性问题回答（WNLI）
5. 语义相似度（STS-B）
6. 多模态推理（MNLI）
7. 机器翻译质量评估（QQP）
8. 情感分析（SST-2）
9. 命名实体识别（WNER）

# slice_list

![image-20240308171231856](杂学.assets/image-20240308171231856.png)

# 查看model占用大小

```python
import torch

# 假设您的模型已经在GPU上
model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True, device_map="auto")
# 获取模型在GPU上占用的内存大小
gpu_memory_usage = torch.cuda.memory_allocated()
print(f"GPU memory usage: {gpu_memory_usage} bytes")

```

##### huozi3 32bit:47g/卡

![image-20240504023105118](杂学.assets/image-20240504023105118.png)

![image-20240504025837348](杂学.assets/image-20240504025837348.png)

请修改爱因斯坦的专业是医学

model.config

```
MixtralConfig {
  "_name_or_path": "/home/share/models/huozi3",
  "architectures": [
    "MixtralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mixtral",
  "num_attention_heads": 32,
  "num_experts_per_tok": 2,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "num_local_experts": 8,
  "output_router_logits": false,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "router_aux_loss_coef": 0.02,
  "router_jitter_noise": 0.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.40.1",
  "use_cache": true,
  "vocab_size": 57002
}
```

##### huozi3 16bit:71G

![image-20240504025957917](杂学.assets/image-20240504025957917.png)

![image-20240504025259229](杂学.assets/image-20240504025259229.png)

![image-20240504025410311](杂学.assets/image-20240504025410311.png)

# model 访问网络参数

mistral-7b

![image-20240506215007240](杂学.assets/image-20240506215007240.png)

- ```python
  w = nethook.get_parameter(model,'transformer.h.5.mlp.fc_out.weight')
  ```

- ```
  model.parameters()
  ```

  

- ```python
  model.state_dict()['linear_relu_stack.0.weight'].data
  ```

  ```
  huozi3 32bit:
  OrderedDict([('model.embed_tokens.weight', tensor([[-2.1267e-04,  1.1215e-03, -1.3733e-03,  ...,  1.1063e-03,
           -2.3651e-03,  1.8501e-04],
          [-1.4343e-02, -9.0790e-04, -9.8267e-03,  ..., -2.6245e-03,
           -1.3062e-02,  3.0823e-03],
          [-8.1635e-04, -1.5182e-03, -8.4305e-04,  ..., -7.2098e-04,
           -7.5912e-04, -5.4550e-04],
          ...,
          [-1.1230e-02,  2.5940e-03, -7.9956e-03,  ...,  4.7302e-03,
            2.8610e-04, -3.7231e-03],
          [ 3.0708e-04, -1.1444e-04,  3.4904e-04,  ...,  3.5477e-04,
            1.1110e-04, -8.9169e-05],
          [ 3.8910e-04, -2.4986e-04,  3.4714e-04,  ...,  2.8992e-04,
           -1.5163e-04, -2.2602e-04]], device='cuda:0')), ('model.layers.0.self_attn.q_proj.weight', tensor([[-5.4626e-03, -5.4626e-03, -5.4626e-03,  ...,  1.2390e-02,
            2.1160e-06,  8.0566e-03],
          [ 4.6692e-03,  4.6692e-03, -2.6524e-06,  ..., -8.9722e-03,
            2.6226e-06, -4.3945e-03],
          [-9.6560e-06, -1.4893e-02,  6.4075e-07,  ..., -8.8289e-07,
            8.6427e-06,  6.1646e-03],
          ...,
          [-3.1433e-03, -6.4087e-03, -3.1128e-03,  ...,  4.5776e-03,
            2.2054e-05,  2.1362e-03],
          [ 1.2268e-02,  1.8799e-02,  6.1340e-03,  ..., -2.4048e-02,
           -5.5237e-03, -1.7456e-02],
          [ 2.6855e-03,  5.4626e-03,  2.6550e-03,  ..., -5.0049e-03,
           -2.3723e-05, -2.3346e-03]], device='cuda:0')
  ```

  

- ```python
      # 加载BERT模型
      model = BertModel.from_pretrained('bert-base-uncased')
  
      # 打印模型参数
      for name, param in model.named_parameters():
          print(f"{name}@@@{param.shape}")
          print()
          
     for name, module in model.named_modules():
          print(f"{name}@@@{module}")
          print()
  ```

  

##### huozi3:32bit

![image-20240504024532570](杂学.assets/image-20240504024532570.png)

![image-20240504024234120](杂学.assets/image-20240504024234120.png)

![image-20240504023247114](杂学.assets/image-20240504023247114.png)

![image-20240504023519685](杂学.assets/image-20240504023519685.png)

![image-20240504023555935](杂学.assets/image-20240504023555935.png)

##### huozi3 :16bit

![image-20240504030358331](杂学.assets/image-20240504030358331.png)

```
MixtralConfig {
  "_name_or_path": "/home/share/models/huozi3",
  "architectures": [
    "MixtralForCausalLM"
  ],
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 32768,
  "model_type": "mixtral",
  "num_attention_heads": 32,
  "num_experts_per_tok": 2,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "num_local_experts": 8,
  "output_router_logits": false,
  "rms_norm_eps": 1e-05,
  "rope_theta": 1000000.0,
  "router_aux_loss_coef": 0.02,
  "router_jitter_noise": 0.0,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.40.1",
  "use_cache": true,
  "vocab_size": 57002
}

```

![image-20240504030223629](杂学.assets/image-20240504030223629.png)

![image-20240504030311843](杂学.assets/image-20240504030311843.png)

##### huozi3: 4bit

![image-20240504030607652](杂学.assets/image-20240504030607652.png)

![image-20240504021603171](杂学.assets/image-20240504021603171.png)

发现4096*14336/2=29360128

所以是1个uint8拆成2个4bit，即29360128 * 1 * 2个4bit数来表示Linear4bit这个矩阵的权重（409614336）

![image-20240504021943707](杂学.assets/image-20240504021943707.png)



llama3:

```json
LlamaConfig {
  "_name_or_path": "./MODELS/models--FlagAlpha--Llama3-Chinese-8B-Instruct/snapshots/d76c4a5d365b041d1b440337dbf7da9664a464fc",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "auto_map": {
    "AutoConfig": "configuration_llama.LlamaConfig",
    "AutoModel": "modeling_llama.LlamaForCausalLM",
    "AutoModelForCausalLM": "modeling_llama.LlamaForCausalLM",
    "AutoModelForSequenceClassification": "modeling_llama.LlamaForSequenceClassification"
  },
  "bos_token_id": 128000,
  "eos_token_id": 128001,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 14336,
  "max_position_embeddings": 8192,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 8,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 500000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.40.1",
  "use_cache": true,
  "vocab_size": 128256
}
```



# xpinyin

```python
from xpinyin import Pinyin

# 创建 Pinyin 对象
p = Pinyin()

# 将汉字转换为带声调的拼音
pinyin_with_tone = p.get_pinyin("你好", tone_marks=True)
print("带声调的拼音：", pinyin_with_tone)

# 将汉字转换为不带声调的拼音
pinyin_without_tone = p.get_pinyin("你好")
print("不带声调的拼音：", pinyin_without_tone)

# 将汉字转换为首字母缩写
initials = p.get_initials("你好")
print("首字母缩写：", initials)
```

# 清华源

```bash
pip install xxx -i https://pypi.tuna.tsinghua.edu.cn/simple
```



# 远程连接

远程登录工具允许用户从一台计算机远程连接到另一台计算机，这在 IT 行业和网络管理中非常常见。这些工具通常提供终端访问、文件传输、以及远程控制等功能。以下是一些流行的远程登录工具：
1. **SSH (Secure Shell)**: SSH 是最常用的远程登录协议之一，提供加密的网络连接。它通常通过命令行界面使用，但也有一些图形界面的客户端，如 PuTTY。
2. **Telnet**: Telnet 是一个早期的网络协议，用于远程登录到计算机系统。但由于其数据传输不加密，现在很少使用。
3. **VNC (Virtual Network Computing)**: VNC 允许用户远程控制另一台计算机的桌面环境。它适合需要图形用户界面的场景。
4. **RDP (Remote Desktop Protocol)**: RDP 是微软开发的协议，用于 Windows 系统的远程桌面连接。它提供了丰富的图形用户界面和良好的用户体验。
5. **TeamViewer**: TeamViewer 是一个流行的远程控制软件，支持跨平台的文件传输和远程控制。
6. **AnyDesk**: AnyDesk 是另一款远程桌面工具，以其高速和轻量级特性而闻名。
7. **Chrome Remote Desktop**: 谷歌的 Chrome Remote Desktop 允许用户通过 Chrome 浏览器或专门的客户端远程访问其他计算机。
8. **Splashtop**: Splashtop 是一款远程桌面软件，提供高性能的远程访问和远程控制功能。
9. **Microsoft Remote Desktop**: 微软提供的官方远程桌面客户端，用于连接到 Windows 远程桌面。
10. **TightVNC**: TightVNC 是一款开源的 VNC 软件，提供远程桌面功能。
11. **X2Go**: X2Go 是一个开源远程桌面软件，基于 NX 服务器技术，提供瘦客户端解决方案。
12. **NoMachine**: NoMachine 是一个高性能的远程桌面和应用程序交付解决方案。
这些工具各有特点，适用于不同的场景和需求。选择合适的远程登录工具时，需要考虑安全性、性能、易用性以及是否支持所需的特定功能。

# logit len

[interpreting GPT: the logit lens — AI Alignment Forum](https://www.alignmentforum.org/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens)

重复现象的解释：残差连接；权重衰减：使得f(x)小。保留了x的特性。这是为了分散任务到各个层。



KL散度不对称，也不符合三角不等式。





# Transformers库学习

[CSDN1](https://blog.csdn.net/qq_44665283/article/details/133963667)

## pipeline

目前，pipeline中支持的任务类型包括：

- 情感分析（sentiment-analysis）：对给定的文本分析其情感极性

- 文本生成（text-generation）：根据给定的文本进行生成

- 命名实体识别（ner）：标记句子中的实体

- 阅读理解（question-answering）：给定上下文与问题，从上下文中抽取答案

- 掩码填充（fill-mask）：填充给定文本中的掩码词

- 文本摘要（summarization）：生成一段长文本的摘要

- 机器翻译（translation）：将文本翻译成另一种语言

- 特征提取（feature-extraction）：生成给定文本的张量表示

  

```python
# audio-classification是任务名
# 'impl': <class 'transformers.pipelines.audio_classification.AudioClassificationPipeline' 指的是此pipeline实现类
# 'tf': ()  指没有用tf进行实现
# ''pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>  指的是模型以pytorch的实现类
# default表示默认的模型
# 'type': 'audio' 指的是任务类型

1 	 audio-classification 	 {'impl': <class 'transformers.pipelines.audio_classification.AudioClassificationPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForAudioClassification'>,), 'default': {'model': {'pt': ('superb/wav2vec2-base-superb-ks', '372e048')}}, 'type': 'audio'}
2 	 automatic-speech-recognition 	 {'impl': <class 'transformers.pipelines.automatic_speech_recognition.AutomaticSpeechRecognitionPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForCTC'>, <class 'transformers.models.auto.modeling_auto.AutoModelForSpeechSeq2Seq'>), 'default': {'model': {'pt': ('facebook/wav2vec2-base-960h', '55bb623')}}, 'type': 'multimodal'}
3 	 text-to-audio 	 {'impl': <class 'transformers.pipelines.text_to_audio.TextToAudioPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForTextToWaveform'>, <class 'transformers.models.auto.modeling_auto.AutoModelForTextToSpectrogram'>), 'default': {'model': {'pt': ('suno/bark-small', '645cfba')}}, 'type': 'text'}
4 	 feature-extraction 	 {'impl': <class 'transformers.pipelines.feature_extraction.FeatureExtractionPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModel'>,), 'default': {'model': {'pt': ('distilbert-base-cased', '935ac13'), 'tf': ('distilbert-base-cased', '935ac13')}}, 'type': 'multimodal'}
5 	 text-classification 	 {'impl': <class 'transformers.pipelines.text_classification.TextClassificationPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>,), 'default': {'model': {'pt': ('distilbert-base-uncased-finetuned-sst-2-english', 'af0f99b'), 'tf': ('distilbert-base-uncased-finetuned-sst-2-english', 'af0f99b')}}, 'type': 'text'}
6 	 token-classification 	 {'impl': <class 'transformers.pipelines.token_classification.TokenClassificationPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForTokenClassification'>,), 'default': {'model': {'pt': ('dbmdz/bert-large-cased-finetuned-conll03-english', 'f2482bf'), 'tf': ('dbmdz/bert-large-cased-finetuned-conll03-english', 'f2482bf')}}, 'type': 'text'}
7 	 question-answering 	 {'impl': <class 'transformers.pipelines.question_answering.QuestionAnsweringPipeline'>, 'tf': (), 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForQuestionAnswering'>,), 'default': {'model': {'pt': ('distilbert-base-cased-distilled-squad', '626af31'), 'tf': ('distilbert-base-cased-distilled-squad', '626af31')}}, 'type': 'text'}
8 	 table-question-answering 	 {'impl': <class 'transformers.pipelines.table_question_answering.TableQuestionAnsweringPipeline'>, 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForTableQuestionAnswering'>,), 'tf': (), 'default': {'model': {'pt': ('google/tapas-base-finetuned-wtq', '69ceee2'), 'tf': ('google/tapas-base-finetuned-wtq', '69ceee2')}}, 'type': 'text'}
9 	 visual-question-answering 	 {'impl': <class 'transformers.pipelines.visual_question_answering.VisualQuestionAnsweringPipeline'>, 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForVisualQuestionAnswering'>,), 'tf': (), 'default': {'model': {'pt': ('dandelin/vilt-b32-finetuned-vqa', '4355f59')}}, 'type': 'multimodal'}
10 	 document-question-answering 	 {'impl': <class 'transformers.pipelines.document_question_answering.DocumentQuestionAnsweringPipeline'>, 'pt': (<class 'transformers.models.auto.modeling_auto.AutoModelForDocumentQuestionAnswering'>,), 'tf': (), 'default': {'model': {'pt': ('impira/layoutlm-document-qa', '52e01b3')}}, 'type': 'multimodal'}
......

```

# asyncio

[Python中协程异步IO（asyncio）详解 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/59621713)

异步IO：就是发起一个IO操作（如：网络请求，文件读写等），这些操作一般是比较耗时的，不用等待它结束，可以继续做其他事情，结束时会发来通知。

协程：又称为微线程，在一个线程中执行，执行函数时可以随时中断，由程序（用户）自身控制，执行效率极高，与多线程比较，没有切换线程的开销和多线程锁机制。

python中异步IO操作是通过asyncio来实现的。



必须先调用next()函数预激活协程，不然send()函数无法使用。

# \033

```
print("\033[34mReceived: ",message,"\033[0m")
\033[0;37;44m
```

[Python \033[95m print打印设置字体颜色_python033-CSDN博客](https://blog.csdn.net/c_lanxiaofang/article/details/126107796)

# pytorch

tensor.untyped_storage().nbytes()

```

在PyTorch中，tensor.untyped_storage().nbytes() 是一个用于获取张量（tensor）占用的存储空间大小的函数。这里的每一部分的意思是：

tensor：这是你要查询的张量对象。
untyped_storage()：这个方法返回张量所使用的存储（storage）对象，而不考虑其数据类型。在PyTorch中，存储是张量数据的基础容器。
nbytes()：这个方法返回存储对象占用的字节数。
```

模型保存：
![image-20240514223434868](杂学.assets/image-20240514223434868.png)

看torch的save_file:

![image-20240514223608179](杂学.assets/image-20240514223608179.png)

```
用中文回答我：torch在调用_save_pretrained时，我设置了保存路径是：
/home/hsong/BS/MODELS/models--FlagAlpha--Llama3-Chinese-8B-Instruct/snapshots/d76c4a5d365b041d1b440337dbf7da9664a464fc

为什么却在../../blobs中发现了写文件的记录，而在我的保存路径中却还是显示之前的日期：
(base) hsong@hpc-login-01:~/BS/MODELS/models--FlagAlpha--Llama3-Chinese-8B-Instruct$ ls -l /home/hsong/BS/MODELS/models--FlagAlpha--Llama3-Chinese-8B-Instruct/blobs
total 15693698
-rw-r--r-- 1 hsong hpc      23950 May 14 23:11 0fd8120f1c6acddc268ebc2583058efaf699a771
-rw-r--r-- 1 hsong hpc 4976698592 May 14 22:58 2373338010ce6bc4d9017de64e6d5b671c4b3863b262278759df03dc10f2ad31
-rw-r--r-- 1 hsong hpc 4915916080 May 14 23:06 26aba83f494bd3374dd9aad3b96f3206e58ad6403a0b03a8f6165ff35bfef5fb
-rw-r--r-- 1 hsong hpc 1168138808 May 14 23:10 4c6c8471a02d2f3aa8298b777e386a7944dca2a8e6d4e9315cedd5e274408992
-rw-r--r-- 1 hsong hpc      51187 May 14 23:19 57771754088b283bd5f6405618e54b39b589d9b8
-rw-r--r-- 1 hsong hpc    9084758 May 14 21:17 5c903c017d75658b8abbbf5a4b0ad1d5bb595d55
-rw-r--r-- 1 hsong hpc 4999802616 May 14 23:06 635b0d290871d0b45204b5f61e936c6090bc2f0d5f98d5c433a1c7510f983bee
-rw-r--r-- 1 hsong hpc        335 May 14 23:19 cfabacc2620186cd3dd4b1dde9a37e057208636e
-rw-r--r-- 1 hsong hpc       1055 May 14 22:38 d772821d27a417a907562eb6158690bf9ec192a6
-rw-r--r-- 1 hsong hpc        121 May 14 22:39 f4e8f8b98888b934c5d4076b3b1a79038398787e

(base) hsong@hpc-login-01:~/BS/MODELS/models--FlagAlpha--Llama3-Chinese-8B-Instruct$ ls -l /home/hsong/BS/MODELS/models--FlagAlpha--Llama3-Chinese-8B-Instruct/snapshots/d76c4a5d365b041d1b440337dbf7da9664a464fc
total 5
lrwxrwxrwx 1 hsong hpc 52 May  9 07:09 config.json -> ../../blobs/d772821d27a417a907562eb6158690bf9ec192a6
lrwxrwxrwx 1 hsong hpc 52 May  9 07:09 generation_config.json -> ../../blobs/f4e8f8b98888b934c5d4076b3b1a79038398787e
lrwxrwxrwx 1 hsong hpc 76 May  9 07:09 model-00001-of-00004.safetensors -> ../../blobs/2373338010ce6bc4d9017de64e6d5b671c4b3863b262278759df03dc10f2ad31
lrwxrwxrwx 1 hsong hpc 76 May  9 07:09 model-00002-of-00004.safetensors -> ../../blobs/635b0d290871d0b45204b5f61e936c6090bc2f0d5f98d5c433a1c7510f983bee
lrwxrwxrwx 1 hsong hpc 76 May  9 07:09 model-00003-of-00004.safetensors -> ../../blobs/26aba83f494bd3374dd9aad3b96f3206e58ad6403a0b03a8f6165ff35bfef5fb
lrwxrwxrwx 1 hsong hpc 76 May  9 07:09 model-00004-of-00004.safetensors -> ../../blobs/4c6c8471a02d2f3aa8298b777e386a7944dca2a8e6d4e9315cedd5e274408992
lrwxrwxrwx 1 hsong hpc 52 May  9 07:09 model.safetensors.index.json -> ../../blobs/0fd8120f1c6acddc268ebc2583058efaf699a771
lrwxrwxrwx 1 hsong hpc 52 May  9 07:09 special_tokens_map.json -> ../../blobs/cfabacc2620186cd3dd4b1dde9a37e057208636e
lrwxrwxrwx 1 hsong hpc 52 May  9 07:09 tokenizer_config.json -> ../../blobs/57771754088b283bd5f6405618e54b39b589d9b8
lrwxrwxrwx 1 hsong hpc 52 May  9 07:09 tokenizer.json -> ../../blobs/5c903c017d75658b8abbbf5a4b0ad1d5bb595d55

```

# DEBUG

```python
    parser = argparse.ArgumentParser()
    parser.add_argument('--editing_method', type=str, required=True)  # KN, ROME, MEMIT
    parser.add_argument('--model', type=str, required=True)  # gpt-j-6B, llama-7b
    parser.add_argument('--dataset_dir', type=str, required=True)  # '/home/hsong/BS/DATA/editing-data/data/portability/One Hop'
    parser.add_argument('--dataset_name', type=str, required=True)  # zsre_mend_eval_portability_gpt4.json
    parser.add_argument('--dataset_size', type=int)  # 
    parser.add_argument('--SAVE_MODE', type=bool, required=True)
    parser.add_argument('--SAVE_PATH', type=str, required=True)
    
    parser.add_argument('-d', '--debug', action='store_true', help='debug mode')
        
    args, _ = parser.parse_known_args()
    
    if args.debug:
        # if you use vscode on hpc-login-01
        import debugpy
        
        debugpy.connect(('192.168.1.50', 6789))
        debugpy.wait_for_client()
        debugpy.breakpoint()
```
